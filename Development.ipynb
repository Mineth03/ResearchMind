{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c074f68",
   "metadata": {},
   "source": [
    "## Imports and API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7aaff64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import feedparser\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "client = OpenAI()\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7571fd9",
   "metadata": {},
   "source": [
    "## ArVix search agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f2779af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_arxiv(query, max_results=5):\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={query}&start=0&max_results={max_results}'\n",
    "    feed = feedparser.parse(requests.get(url).text)\n",
    "    \n",
    "    results = []\n",
    "    for entry in feed.entries:\n",
    "        results.append({\n",
    "            'title': entry.title,\n",
    "            'summary': entry.summary,\n",
    "            'link': entry.link\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b934320",
   "metadata": {},
   "source": [
    "## OpenAlex search agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b35cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_openalex(query, max_results=5):\n",
    "    url = f\"https://api.openalex.org/works?search={query}&per-page={max_results}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    results = []\n",
    "    for item in data.get('results', []):\n",
    "        results.append({\n",
    "            'title': item.get('display_name', 'No Title'),\n",
    "            'summary': item.get('abstract_inverted_index', {}),\n",
    "            'link': item.get('id', 'No Link')\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83157985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_results(arxiv_results, openalex_results):\n",
    "    return arxiv_results + openalex_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6928a2",
   "metadata": {},
   "source": [
    "## Summerizing agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08d9e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_papers(papers):\n",
    "    content = \"\\n\\n\".join([f\"Title: {p['title']}\\nSummary: {p['summary']}\" for p in papers])\n",
    "    prompt = f\"Summarize the following research papers:\\n{content}\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f39ef5c",
   "metadata": {},
   "source": [
    "## Critic Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8dee186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def critique_summary(summary_text):\n",
    "    prompt = (\n",
    "        \"Review the following summary for bias, missing key points, or factual errors. \"\n",
    "        \"Suggest improvements clearly:\\n\\n\"\n",
    "        f\"{summary_text}\"\n",
    "    )\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    critique = response.choices[0].message.content\n",
    "    \n",
    "    if any(keyword in critique.lower() for keyword in [\"missing\", \"improve\", \"bias\", \"error\"]):\n",
    "        return critique, 'needs_rewrite'\n",
    "    else:\n",
    "        return critique, 'approved'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8d2f8b",
   "metadata": {},
   "source": [
    "## Verifier agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c86e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_summary(summary_text):\n",
    "    prompt = (\n",
    "        \"Fact-check the following summary. \"\n",
    "        \"Highlight any factual inaccuracies or unsupported claims:\\n\\n\"\n",
    "        f\"{summary_text}\"\n",
    "    )\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25b558d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_final_answer(summary, critique, verification):\n",
    "    return f\"Summary:\\n{summary}\\n\\nCritique:\\n{critique}\\n\\nVerification Notes:\\n{verification}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2421aed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critique suggests improvements. Re-summarizing...\n",
      "Summary:\n",
      "Title: Innovating for Tomorrow: The Convergence of SE and Green AI\n",
      "This paper discusses how advancements in machine learning are impacting software engineering processes, with a focus on creating environmentally friendly AI-enabled software systems.\n",
      "\n",
      "Title: Reflection on Data Storytelling Tools in the Generative AI Era from the Human-AI Collaboration Perspective\n",
      "The paper explores the use of generative AI techniques in data storytelling tools and analyzes collaboration patterns between humans and AI, highlighting opportunities for future innovation.\n",
      "\n",
      "Title: WordDecipher: Enhancing Digital Workspace Communication with Explainable AI for Non-native English Speakers\n",
      "This paper presents WordDecipher, an explainable AI tool designed to improve communication for non-native English speakers in digital workspaces by providing rewriting suggestions aligned with users' intentions.\n",
      "\n",
      "Title: Big data in healthcare: management, analysis and future prospects\n",
      "The paper discusses the importance of big data in healthcare management and analysis, highlighting the challenges and opportunities associated with handling large amounts of data to improve patient services.\n",
      "\n",
      "Title: Towards a semantic Construction Digital Twin: Directions for future research\n",
      "This paper explores the role of semantic models in enhancing efficiency and minimizing environmental impacts in the construction industry, with a focus on digital twin technology and the need for holistic, scalable approaches in research.\n",
      "\n",
      "Critique:\n",
      "Overall, the summaries provide a good overview of the topics discussed in the papers. However, there are some areas for improvement to avoid bias or missing key points.\n",
      "\n",
      "1. Innovating for Tomorrow: The Convergence of SE and Green AI\n",
      "- The summary should mention any potential drawbacks or challenges related to creating environmentally friendly AI-enabled software systems, in addition to discussing the positive impacts.\n",
      "- It would be beneficial to include examples of real-world applications or case studies to illustrate the convergence of software engineering and green AI.\n",
      "\n",
      "2. Reflection on Data Storytelling Tools in the Generative AI Era from the Human-AI Collaboration Perspective\n",
      "- The summary could benefit from mentioning any limitations or ethical considerations associated with using generative AI techniques in data storytelling tools.\n",
      "- Providing concrete examples of successful human-AI collaborations in data storytelling would enhance the discussion on future innovation opportunities.\n",
      "\n",
      "3. WordDecipher: Enhancing Digital Workspace Communication with Explainable AI for Non-native English Speakers\n",
      "- The summary should include information on the effectiveness or potential challenges of WordDecipher in improving communication for non-native English speakers.\n",
      "- It would be helpful to address any concerns regarding privacy or data security associated with using AI tools like WordDecipher in digital workspaces.\n",
      "\n",
      "4. Big data in healthcare: management, analysis and future prospects\n",
      "- The summary could mention specific examples of how big data is currently being used in healthcare management and analysis to improve patient services.\n",
      "- Including a discussion on potential privacy concerns or issues related to handling large amounts of patient data would provide a more comprehensive view of the topic.\n",
      "\n",
      "5. Towards a semantic Construction Digital Twin: Directions for future research\n",
      "- The summary should address potential challenges or limitations in implementing semantic models for construction digital twins, in addition to discussing benefits.\n",
      "- Providing examples of how digital twins have been successfully utilized in the construction industry would help illustrate the need for holistic, scalable research approaches.\n",
      "\n",
      "Verification Notes:\n",
      "The summaries provided appear to accurately capture the main topics and focus of each paper. No factual inaccuracies or unsupported claims were identified in the summaries.\n"
     ]
    }
   ],
   "source": [
    "# Example Query\n",
    "query = \"latest advancements in AI alignment\"\n",
    "\n",
    "# Step 1: Search\n",
    "arxiv_results = search_arxiv(query, max_results=3)\n",
    "openalex_results = search_openalex(query, max_results=3)\n",
    "merged_results = merge_results(arxiv_results, openalex_results)\n",
    "\n",
    "# Step 2: Summarize\n",
    "summary = summarize_papers(merged_results)\n",
    "\n",
    "# Step 3: Critique with loop if needed\n",
    "critique, status = critique_summary(summary)\n",
    "if status == 'needs_rewrite':\n",
    "    print(\"Critique suggests improvements. Re-summarizing...\")\n",
    "    summary = summarize_papers(merged_results)\n",
    "    critique, status = critique_summary(summary)\n",
    "\n",
    "# Step 4: Verify\n",
    "verification = verify_summary(summary)\n",
    "\n",
    "# Step 5: Final Answer\n",
    "final_output = compose_final_answer(summary, critique, verification)\n",
    "print(final_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
